# Описание экспериментов с RNN для бинарной классификации токсичных комментариев

Для экспериментов были взяты модели LSTM и GRU. Всего было проведено 3 экспериента над обеими моделями:
1. Обучение на эмбеддингах из предобученного Word2Vec из сырого текста
2. Обучение на собственных эмбеддингах, полученных из предобработанного текста (алгоритм для предобработки из чекпоинта 5)
3. Обучение на эмбеддингах из предобученной DistilBERT (distilbert-base-uncased)

В первом случае обе модели показали примерно одинаковый результат, F1 в районе 0.48, это хуже, чем ML-модели.

При обучении на эмбеддингах предобученной DistilBERT метрика выросла до 0.504 и 0.51 на тестовых данных для LSTM и GRU соответственно.

Обучение на собственных эмбеддингах дало наибольший прирост, и лучшие модели, полученные в ходе обучения выдали значение метрики 0.613 на тестовых данных, что лучше, чем любая линейная модель, но все еще хуже лучшей нелинейной (XGBoost).

| Модель                   | Val   | Test  |
|--------------------------|-------|-------|
| LSTM + W2V               | 0.453 | 0.488 |
| GRU + W2V                | 0.452 | 0.487 |
| LSTM + DistilBERT эмбед. | 0.485 | 0.504 |
| GRU + DistilBERT эмбед.  | 0.491 | 0.51  |
| LSTM + Собств. эмбед.    | 0.576 | 0.613 |
| GRU + Собств. эмбед.     | 0.583 | 0.613 |

По итогам экспериментов с RNN моделями лучшим оказался вариант обучения GRU и LSTM на собственных эмбеддигах, полученных из предобработанного текста.
