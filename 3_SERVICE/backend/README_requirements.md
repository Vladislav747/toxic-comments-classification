# Описание зависимостей проекта

Данный файл содержит подробное описание всех библиотек, используемых в backend части проекта классификации токсичных комментариев.

## Веб-фреймворк и API

### uvicorn (~0.34.0)
Высокопроизводительный ASGI сервер для запуска FastAPI приложения в продакшене с поддержкой асинхронности.

### python-multipart (~0.0.20)
Библиотека для обработки multipart/form-data запросов, необходима для загрузки файлов через веб-формы.

## Машинное обучение и обработка данных

### scikit-learn (~1.5.2)
Основная библиотека машинного обучения, используется для:
- Классических алгоритмов классификации (LogisticRegression, SVC, MultinomialNB)
- Векторизации текста (TF-IDF, Bag of Words)
- Метрик оценки качества моделей
- Разделения данных на train/test

### pandas (~2.2.3)
Библиотека для работы с табличными данными:
- Загрузка и обработка датасетов с комментариями
- Анализ и предобработка данных
- Манипуляции с DataFrame для подготовки данных к обучению

### cloudpickle (~3.1.0)
Расширенная версия pickle для сериализации сложных объектов:
- Сохранение и загрузка обученных ML моделей
- Сериализация pipeline'ов обработки данных
- Поддержка лямбда-функций и вложенных объектов

## Обработка естественного языка (NLP)

### spacy (~3.8.3)
Продвинутая библиотека NLP для:
- Токенизации и сегментации текста
- Лемматизации и нормализации слов
- Извлечения лингвистических признаков
- Предобработки текста перед векторизацией

### nltk (~3.9.1)
Классическая библиотека обработки естественного языка:
- Удаление стоп-слов
- Стемминг и лемматизация
- Токенизация текста
- Корпуса данных для обучения

### transformers (~4.52.4)
Библиотека Hugging Face для работы с трансформерными моделями:
- Предобученные модели BERT, DistilBERT, DeBERTa
- Токенизация для трансформерных архитектур
- Fine-tuning моделей для классификации текста
- Inference с использованием GPU/CPU

### sentencepiece (~0.2.0)
Токенизатор на уровне подслов (транзитивная зависимость transformers):
- Автоматически используется transformers для subword tokenization
- Необходима для работы с BERT, DistilBERT и подобными моделями
- Разбивает текст на более мелкие единицы для улучшения качества NLP

### protobuf (~6.31.1)
Система сериализации данных (транзитивная зависимость transformers):
- Автоматически используется для сохранения/загрузки моделей
- Protocol Buffers для компактного хранения конфигураций моделей
- Эффективная сериализация структурированных данных

## База данных

### sqlalchemy (~2.0.41)
ORM (Object-Relational Mapping) для работы с базами данных:
- Определение моделей данных (BgTask, Model)
- Асинхронные операции с базой данных
- Типизированные запросы с поддержкой современного Python

### alembic (~1.16.1)
Инструмент миграций для SQLAlchemy:
- Управление схемой базы данных
- Версионирование изменений в структуре БД
- Автоматическая генерация миграций

### asyncpg (~0.30.0)
Асинхронный драйвер PostgreSQL:
- Высокопроизводительное подключение к PostgreSQL
- Поддержка asyncio и асинхронных операций
- Оптимизированные запросы к базе данных

### greenlet (~3.2.2)
Библиотека для поддержки корутин (транзитивная зависимость SQLAlchemy):
- Автоматически используется SQLAlchemy для асинхронной работы
- Обеспечивает псевдо-синхронный API поверх asyncio
- Необходима для AsyncSession и async_sessionmaker

## Архитектура проекта

Все эти библиотеки работают вместе для создания полнофункционального ML-сервиса:

1. **Веб-слой**: FastAPI + Pydantic + uvicorn обеспечивают REST API
2. **ML-слой**: scikit-learn + transformers для классических и deep learning моделей
3. **NLP-слой**: spacy + nltk + transformers для обработки текста
4. **Персистентность**: SQLAlchemy + PostgreSQL для хранения метаданных
5. **Сериализация**: cloudpickle для классических моделей

Такая архитектура позволяет обрабатывать текстовые данные, обучать модели различных типов и предоставлять API для классификации токсичности комментариев в режиме реального времени.

## Зависимости, которые можно оптимизировать

### Неиспользуемые
- **python-slugify** - можно удалить из requirements.txt

### Транзитивные зависимости (устанавливаются автоматически)
- **sentencepiece** и **protobuf** - зависимости transformers
- **greenlet** - зависимость SQLAlchemy для асинхронной работы

*Примечание: Транзитивные зависимости можно убрать из requirements.txt, они установятся автоматически при установке основных библиотек.*

