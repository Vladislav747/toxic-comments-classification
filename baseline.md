1. Выбор метрик качества
Для оценки качества моделей были выбраны ключевые метрики, такие как F1-мера, точность (precision), полнота (recall) и ROC-AUC, что позволило учесть дисбаланс в датасете и специфику задачи multi-label классификации.
Также дополнительно строились графики ROC-AUC для наглядности демонстрации успешности той или иной модели


2. Feature engineering
Проведена глубокая предобработка текстовых данных, включающая токенизацию, стемминг/лемматизацию, а также векторизацию текстов с помощью TF-IDF.
Были созданы дополнительные признаки, такие как ctws.


3. Обучение классических моделей классификации
Обучение проводилось в рамках одноклассовой и multilabel классификации
При обучении мы разбивали датасет на train, validate и test выборку используя подход Out-Of-Time (OOT)
Были обучены классические модели классификации, включая Logistic Regression, Linear SVC, Наивный Байес и модели градиентного бустинга(XGBoost).
Для повышения качества использовался подбор гиперпараметров.


4. Валидация и выбор модели
Результаты моделей валидировались на тестовой и валидационной выборке.
Среди классических моделей Logistic Regression и Linear SVC с TF-IDF векторизацией показали лучшие результаты, уступая бинарной классификации на классе toxicity. Более продвинутые алгоритмы, такие как XGBoost, демонстрируют лучший баланс между precision и recall, обеспечивая более высокую F1-метрику.